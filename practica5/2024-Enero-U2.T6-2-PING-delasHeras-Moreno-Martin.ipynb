{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor: Martín de las Heras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**U2.T6.2.-**\n",
    "\n",
    "La predicción de una situación de salud como la posible presencia de un virus en una persona, o encontrarnos con una persona ante la que dudamos si hay un ataque al corazón o no, es una aplicación de los modelos de ML de aprendizaje supervisado. \n",
    "\n",
    "Siguiendo https://www.kaggle.com/datasets/fedesorianoheart-failure-prediction, las enfermedades cardiovasculares (CVD por sus siglas en inglés) son la primera causa de muerte en el mundo: se calcula que cada año se cobran 17,9 millones de vidas, lo que representa el 31% de todas las muertes en el mundo. Cuatro de cada cinco muertes por CVD se deben a infartos de miocardio y accidentes cerebrovasculares, y un tercio de estas muertes se producen prematuramente en personas menores de 70 años. La insuficiencia cardiaca es un evento común causado por las CVD y este conjunto de datos contiene 11 características que pueden utilizarse para predecir una posible enfermedad cardiaca.\n",
    "\n",
    "Las personas con enfermedades cardiovasculares o que corren un alto riesgo cardiovascular (debido a la presencia de uno o más factores de riesgo como hipertensión, diabetes, hiperlipidemia o enfermedad ya establecida) necesitan una detección y gestión tempranas en las que un modelo de aprendizaje automático puede ser de gran ayuda. \n",
    "(Traducción realizada con la versión gratuita del traductor DeepL.com)\n",
    "\n",
    "La página web \n",
    "\n",
    "https://www.kaggle.com/code/beingamit99/heart-disease-decision-tree \n",
    "\n",
    "es bastante completa como ejemplo de la problemática anterior. Muestra todo el código en PYTHON.\n",
    " \n",
    "**a)** Añadir comentarios al citado código, indicando lo que realiza cada celda o bloque. Comentar si es posible programar alguna celda de manera más eficiente a la que muestra la sintaxis que está en la web anterior. \n",
    "\n",
    "**b)** Interpretar las salidas gráficas que se generan al ejecutar cada una de las celdas. \n",
    "\n",
    "**c)** Incorporar celdas adicionales que mejoren el código tanto en términos de ML, como de Estadística, como de Programación. Por ejemplo, incluir para algunas variables críticas en la problemática CVD, un gráfico del tipo Figura 3 (Penguins Data Pairplot) del documento citado en el ejercicio anterior U2.T6.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Comienza el código importando las diferentes librerías que se van a utilizar, en concreto varias librerías de Kaggle en la primera y en la segunda celdas. A continuación lee el fichero CSV de las enfermedades cardiovasculares y nos muestra por pantalla las primeras filas al igual que su forma.\n",
    "\n",
    "Se renombran las columnas de la base de datos. Y se chequea que los tipos de datos de cada columna sean los correctos. A continuación en la celda 7, se ve cuántas veces se repite cada tipo de dato. Y vemos que más o menos se trata de un conjunto bien distribuido. Es decir que no está desbalanceado.\n",
    "\n",
    "A continuación pasamos a comprobar si existe algún outlayer. Se grafican mediante box plots las diferentes características que hemos que están definidas en el *dataset*. Vemos que están presentes pero son menores, así que comprobamos primero si hay algún dato nulo que tengamos que discriminar. Y a partir de ahí definimos distintos *datasets* en función de las características que nos importan. Vemos la variación de la edad para cada objetivo que tenemos. Y lo gráficamos en un gráfico de barras, también graficamos discriminando en función del sexo.\n",
    "\n",
    "A continuación dividimos en conjunto de test y conjunto de entrenamiento, mostrando también por pantalla las estructuras que tienen.\n",
    "\n",
    "Efectuamos un entrenamiento de un árbol de decisión en función de los datos de entrenamiento y calculamos sus puntuaciones de las predicciones en el conjunto de test.\n",
    "\n",
    "A continuación en la celda 23. Se imprime por pantalla el árbol de decisión que es bastante grande. Con la matriz de confusión. Y a continuación se hace una poda. Para poder. Encontrar una matriz de confusión que sea más correcta. Rol de decisión que sea más pequeño. Para que el coste por complejidad sea mucho menor para ello.\n",
    "\n",
    "Entrenamos los ccp alphas. Y los graficamos para saber cuál es el óptimo que necesitamos de cara a la *accuracy*. Podemos ver que la puntuación en el conjunto de entrenamiento es peor, pero en el conjunto de test es mucho mejor. Esto se debe a que el árbol de decisión estaba efectuando *overfitting* en el conjunto de entrenamiento.\n",
    "\n",
    "De esta manera volvemos a imprimir el árbol de decisión y vemos que es más simple y que además efectúa una clasificación mejor que antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
